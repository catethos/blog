{
  
    
        "post0": {
            "title": "The Two Children Problem",
            "content": "Problem . Mr. Jones has two children. The older child is a girl. What is the probability that both children are girls? | Mr. Smith has two children. At least one of them is a boy. What is the probability that both children are boys? | . Using Python to Represent Probability . class Event: def __init__(self, pred, condition=None): self.pred = pred self.condition = condition def __or__(self, pred): return Event(self.pred, pred.pred) . class Probability: def __init__(self, sample_space): self.sample_space = sample_space def __call__(self, event): if event.condition: num = len({x for x in self.sample_space if event.pred(x) and event.condition(x)}) den = len({x for x in self.sample_space if event.condition(x)}) return num / den else: num = len({x for x in self.sample_space if event.pred(x)}) den = len(self.sample_space) return num/den . Examples . Before solving the two children problem, let&#39;s see of our code can solve the dice problem that we encounter in every introuction to probability course. . Example 1 . Rolling a fair dice with 6 faces, what is the probability of getting a even number ? . sample_space = {1,2,3,4,5,6} p = Probability(sample_space) # define the event of getting an even number is_even = Event(lambda x : x%2 == 0) # the probability of getting even number p(is_even) . 0.5 . Example 2 . (We can also look at conditional probability) What is the probability of getting an even number given the result is greater than 3 . greater_3 = Event(lambda x : x&gt;3) p(is_even | greater_3) . 0.6666666666666666 . Solving the real problem . Let&#39;s denote the gender by either the letter &#39;G&#39;(girl) or &#39;B&#39;(boy), and hence &#39;GB&#39; means the elder child is a girl and the younger is a boy. . sample_space = {&quot;GG&quot;,&quot;GB&quot;,&quot;BG&quot;,&quot;BB&quot;} p = Probability(sample_space) . older_is_boy = Event(lambda x: x[0] == &quot;B&quot;) at_least_one_boy = Event(lambda x: &quot;B&quot; in x) both_boy = Event(lambda x: x.count(&quot;B&quot;) == 2) . p(both_boy | older_is_boy) . 0.5 . p(both_boy | at_least_one_boy) . 0.3333333333333333 .",
            "url": "https://catethos.github.io/blog/probability/2022/05/02/paradox.html",
            "relUrl": "/probability/2022/05/02/paradox.html",
            "date": " • May 2, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "$n$ ways of looking at linear regression ($n$=1)",
            "content": "Problem Setup . Suppose that we want to predict salary based on age, education, gender, job, etc, the common way to set up this problem is to represent the $n$ data points with $m$ features as a matrix: . $$ X = begin{pmatrix} x_{1,1} &amp; x_{1,2} &amp; cdots &amp; x_{1,m} x_{2,1} &amp; x_{2,2} &amp; cdots &amp; x_{2,m} vdots &amp; vdots &amp; ddots &amp; vdots x_{n,1} &amp; x_{n,2} &amp; cdots &amp; x_{n,m} end{pmatrix} $$where $x_{i,1}, x_{i,2}, x_{i,3}, ...$ could be the age, education, job and other features for the $i$-person. . We could also represent the salaries for each person as a vector: . $$ y = begin{pmatrix} y_1 y_2 vdots y_n end{pmatrix} $$Thus linear regression can be thought of finding another vector . $$ beta = begin{pmatrix} beta_1 beta_2 vdots beta_m end{pmatrix} $$such that $$ X beta approx y $$ . We shall define the approximation $ approx$ rigorously later. . Some Linear Algebra . Given that $X in mathbb{R}^{n,m}$, the set $ {Xu| u in mathbb{R}^m }$ forms a linear subspace. . Example 1: Suppose that . $$ X= begin{pmatrix} 1 2 end{pmatrix} $$ then the set $ {Xu| u in mathbb{R} }$ is a straight line . Example 2: Suppose that . $$ X= begin{pmatrix} 1 &amp; 4 2 &amp; 5 3 &amp; 6 end{pmatrix} $$ then set $ {Xu| u in mathbb{R}^2 }$ is a plane . In general, the set $ {Xu| u in mathbb{R}^m }$ is a hyperplane. So if $y$ is on the hyperplane, then by definition there is a $ beta in mathbb{R}^m$ that can satisfy the equation $X beta=y$. . Now suppose $y$ is not on the hyperplane, next best thing we can do is to find a $ hat{y}$ on the hyperplabe that is closest to $y$, which is the orthogonal projection of $y$ onto the plane . . . By the definition of orthogonality, we know that . $$ X^T(y-X beta) = 0 $$and thus $$ beta = (X^TX)^{-1}X^Ty $$ . This is the analytical solution of our linear regression problem. . Now let&#39;s try some concrete example to see if it actually works. Let&#39;s generate 100 random points using the real $ beta=0.2$ and some random noise, and figure out if we can recover the $ beta$ using only $X$ and $y$ . X = randn(100) β = 0.2 y = X*β + randn(100)/10 scatter(X, y) . Now we can calculate using the formula . (X&#39;*X)^-1*X&#39;*y . 0.19280849762611454 . 0.19 is really close to 2 (the real $ beta$) ! The same formula hold for higher dimension. We can&#39;t visualize it, but we can perform the calculation as usual. . X = randn(100,5) β = [0.1,0.2,0.3,0.4,0.5] y = X*β + randn(100)/10 (X&#39;*X)^-1*X&#39;*y . 5-element Vector{Float64}: 0.08658415160224578 0.19121983641861673 0.31556448265297393 0.4116056101763966 0.49374419922975754 . observe that $(0.08, 0.19, 0.32, 0.41, 0.49)$ is really close to $(0.1,0.2,0.3,0.4,0.5)$. .",
            "url": "https://catethos.github.io/blog/linear%20regression/theory/2022/05/01/nways1.html",
            "relUrl": "/linear%20regression/theory/2022/05/01/nways1.html",
            "date": " • May 1, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://catethos.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://catethos.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}